{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from astronomaly.utils.utils import ImageCycler\n",
    "from astronomaly.feature_extraction.power_spectrum import psd_2d\n",
    "from astronomaly.data_management.image_reader import ImageThumbnailsDataset\n",
    "from astronomaly.preprocessing.image_preprocessing import image_transform_scale\n",
    "from astronomaly.postprocessing import scaling\n",
    "from astronomaly.anomaly_detection.human_loop_learning import NeighbourScore, ScoreConverter\n",
    "from astronomaly.anomaly_detection import isolation_forest, lof\n",
    "from astronomaly.feature_extraction import shape_features\n",
    "from astronomaly.dimensionality_reduction import pca\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "presentation_plots = False\n",
    "\n",
    "latex_dpi = 72.27\n",
    "textwidth = 469.75502/latex_dpi\n",
    "textheight = 650.43001/latex_dpi\n",
    "\n",
    "figsize_square = (textwidth/2, textwidth/2)\n",
    "figsize_fullwidth = (textwidth, textwidth/2)\n",
    "figsize_panels = (textwidth, 0.75*textheight/3)\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.family':'serif', 'font.size':10, 'figure.dpi':latex_dpi, 'text.usetex':True,\n",
    "                    'savefig.format':'pdf'})\n",
    "figure_suffix = '.pdf'\n",
    "\n",
    "fig_dir = '../paper/figures/'\n",
    "\n",
    "if presentation_plots:\n",
    "    fig_dir = '../presentation_figures/'\n",
    "    plt.rcParams.update({'font.family':'sans-serif', 'font.size':10, 'figure.dpi':300, 'text.usetex':True,\n",
    "                    'savefig.format':'png'})\n",
    "    presentation_plot_size = (textwidth, 2*textwidth/3)\n",
    "    figure_suffix = '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_weighted_score(y_true, scores, N):\n",
    "    w_i = (N + 1 - np.arange(1, N+1))\n",
    "    S_0 = N/2*(N+1)\n",
    "    \n",
    "    inds = np.argsort(scores)[::-1]\n",
    "#     scores = scores[inds][:N]\n",
    "    y_true = y_true[inds][:N]\n",
    "#     print(y_true, scores)\n",
    "    \n",
    "    I = y_true\n",
    "    \n",
    "    return np.sum(I*w_i)/S_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rws_curve(labels, anomalies, scores, plot=True, N_vals=[]):\n",
    "    \n",
    "#     if plot:\n",
    "#         plt.figure()\n",
    "    \n",
    "    clean_labels = labels.loc[anomalies.index, 'label'].values\n",
    "    print(clean_labels.shape)\n",
    "    print(scores.shape)\n",
    "    if len(N_vals) == 0:\n",
    "        N_vals = np.arange(10, 510, 10)\n",
    "    rws = []\n",
    "    for N in N_vals:\n",
    "        rws.append(rank_weighted_score(clean_labels, scores, N))\n",
    "\n",
    "    rws_150 = rank_weighted_score(clean_labels, scores, 150)\n",
    "\n",
    "    if plot:\n",
    "#         plt.plot(N_vals, rws)\n",
    "        return N_vals, rws\n",
    "    return rws_150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rws(labels, anomalies, scores, N):\n",
    "    clean_labels = labels.loc[anomalies.index, 'label'].values\n",
    "    return rank_weighted_score(clean_labels, scores, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ind_sum(found_inds, all_inds):\n",
    "    this_found_inds = found_inds.copy()\n",
    "    this_found_inds.sort()\n",
    "    out = np.zeros(len(all_inds))\n",
    "    for i in this_found_inds:\n",
    "        out[i:] += 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_sum(anomalies, sort_by='score'):\n",
    "    sorted_inds = anomalies.sort_values(sort_by, ascending=False).index\n",
    "    labs = labels.loc[anomalies.index]\n",
    "    anom_inds = labs[labs['label']==1].index\n",
    "\n",
    "    found_inds= []\n",
    "\n",
    "    for i in anom_inds:\n",
    "        found_inds.append(np.where(sorted_inds==i)[0][0])\n",
    "            \n",
    "    ind_sum = compute_ind_sum(found_inds, sorted_inds)\n",
    "    \n",
    "    return ind_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch to Scattering features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('/Users/mrgr/Documents/GitHub/KiDS_astronomaly/example_data/')\n",
    "image_dir = os.path.join(data_dir, 'KiDS_cutouts', 'ugri_images')\n",
    "\n",
    "# Where output should be stored\n",
    "out_dir = os.path.join(\n",
    "    data_dir, 'astronomaly_output', 'kids_ugri', '')\n",
    "\n",
    "data_dir = image_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale the features with feature scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scl = StandardScaler()\n",
    "# output = scl.fit_transform(features)\n",
    "# features = pd.DataFrame(data=output, index=features.index, \n",
    "#                             columns=features.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get features with Iforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IforestAlgorithm ...\n",
      "Done! Time taken: 1.1689479351043701 s\n"
     ]
    }
   ],
   "source": [
    "pipeline_anomaly = isolation_forest.IforestAlgorithm(output_dir = out_dir, force_rerun=True)\n",
    "anomalies = pipeline_anomaly.run(features)\n",
    "\n",
    "\n",
    "# pipeline_score_converter = ScoreConverter(force_rerun=True, output_dir = out_dir)\n",
    "# anomalies = pipeline_score_converter.run(anomalies)\n",
    "# anomalies = anomalies.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024015.245-284053.94</th>\n",
       "      <td>0.082015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024015.289-284106.07</th>\n",
       "      <td>0.049280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024015.325-283927.71</th>\n",
       "      <td>0.095958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024016.534-284002.35</th>\n",
       "      <td>0.073862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024017.408-283943.43</th>\n",
       "      <td>0.072461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024442.804-283959.75</th>\n",
       "      <td>0.089504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024443.486-284010.61</th>\n",
       "      <td>0.096462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024444.198-284032.84</th>\n",
       "      <td>-0.065023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024445.092-284001.48</th>\n",
       "      <td>0.067909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024445.775-283902.69</th>\n",
       "      <td>0.082371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       score\n",
       "tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024015.245-284...  0.082015\n",
       "tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024015.289-284...  0.049280\n",
       "tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024015.325-283...  0.095958\n",
       "tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024016.534-284...  0.073862\n",
       "tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024017.408-283...  0.072461\n",
       "...                                                      ...\n",
       "tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024442.804-283...  0.089504\n",
       "tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024443.486-284...  0.096462\n",
       "tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024444.198-284... -0.065023\n",
       "tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024445.092-284...  0.067909\n",
       "tile_KIDS_40.6_-28.2_ID_KiDSDR4 J024445.775-283...  0.082371\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_parquet(out_dir + 'FeatureScaler_output.parquet')\n",
    "anomalies = pd.read_parquet(out_dir + 'ScoreConverter_output.parquet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/michelle/BigData/Anomaly/GalaxyZoo/galaxy-zoo-the-galaxy-challenge/training_solutions_rev1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#here i import the dataframe with the labels\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m/home/michelle/BigData/Anomaly/GalaxyZoo/galaxy-zoo-the-galaxy-challenge/training_solutions_rev1.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m df\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mGalaxyID\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m df\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/michelle/BigData/Anomaly/GalaxyZoo/galaxy-zoo-the-galaxy-challenge/training_solutions_rev1.csv'"
     ]
    }
   ],
   "source": [
    "#here i import the dataframe with the labels\n",
    "df = pd.read_csv('/home/michelle/BigData/Anomaly/GalaxyZoo/galaxy-zoo-the-galaxy-challenge/training_solutions_rev1.csv')\n",
    "df=df.set_index('GalaxyID')\n",
    "df.index = df.index.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_key = pd.read_csv('/home/michelle/BigData/Anomaly/GalaxyZoo/KAGGLE_allgals_randomgalaxyid.csv', index_col=0)\n",
    "kaggle_key.index = kaggle_key.index.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feat0', 'feat1', 'feat2', 'feat3', 'feat4', 'feat5', 'feat6', 'feat7',\n",
       "       'feat8', 'feat9',\n",
       "       ...\n",
       "       'feat1270', 'feat1271', 'feat1272', 'feat1273', 'feat1274', 'feat1275',\n",
       "       'feat1276', 'feat1277', 'feat1278', 'feat1279'],\n",
       "      dtype='object', length=1280)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(data=(df['Class6.1']>0.9).astype('int'))\n",
    "labels.columns = ['label']\n",
    "#labels['human_label'] = np.round(df['Class6.1']*5).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61578"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running NeighbourScore ...\n",
      "Done! Time taken: 2.541348695755005 s\n"
     ]
    }
   ],
   "source": [
    "## ONLY label a set once\n",
    "anomalies['human_label'] = [-1]*len(anomalies)\n",
    "inds = anomalies.sort_values('score', ascending=False).index[:200]\n",
    "anomalies.loc[inds, 'human_label'] = labels.loc[inds, 'human_label']\n",
    "\n",
    "ns = NeighbourScore(alpha=0.1, force_rerun=True, output_dir = out_dir)\n",
    "features_with_labels = ns.combine_data_frames(features, anomalies)\n",
    "final_score = ns.run(features_with_labels)\n",
    "anomalies['final_score'] = final_score.trained_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other_df = anomalies[anomalies.human_label==-1]\n",
    "# kaggle_key.loc[other_df.sort_values('final_score', ascending=False).index].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msk = [True]*len(anomalies)\n",
    "msk = anomalies.human_label==-1\n",
    "ind_sum_ml = cumulative_sum(anomalies[msk], sort_by='score')\n",
    "ind_sum_hitl = cumulative_sum(anomalies[msk], sort_by='final_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_sum_ml[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce93345e3ef44b3c8bbbf53bcbb8e52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "if presentation_plots:\n",
    "    figsize = presentation_plot_size\n",
    "else:\n",
    "    figsize = figsize_square\n",
    "    \n",
    "plt.figure(figsize=figsize)\n",
    "x = np.arange(len(anomalies[msk]))\n",
    "# plt.plot(x,x,'k', alpha=0.5)\n",
    "\n",
    "plt.plot(x, ind_sum_hitl, '-', color=cols[0], label='Active learning')\n",
    "plt.plot(x, ind_sum_ml, '-', color=cols[1], label='No active learning')\n",
    "rand_inds = np.random.choice(x, replace=False, size=labels.label.sum())\n",
    "plt.plot(x, compute_ind_sum(rand_inds, x), '-k', alpha=0.2, label='Random')\n",
    "\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,2000])\n",
    "plt.ylim([0,300])\n",
    "plt.xlabel('Index in ranked list')\n",
    "plt.ylabel('Number of anomalies detected')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(fig_dir + 'galaxy_cumulative' + figure_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(x, ind_sum_hitl/ind_sum_ml, '-', color=cols[0])\n",
    "# plt.xlim([0,2000])\n",
    "# plt.ylabel('Ratio active learning to machine learning')\n",
    "# plt.xlabel('Index in ranked list')\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.savefig(fig_dir + 'galaxy_ratio_with_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare RWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ae1f0045ca4eeb90fade9cd4f5898d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Before any active learning\n",
    "scores = anomalies.score.values\n",
    "N_vals = np.arange(10, 510, 10)\n",
    "N_vals, rws_before = make_rws_curve(labels, anomalies, scores, plot=True, N_vals=N_vals)\n",
    "N_vals, rws_after = make_rws_curve(labels, anomalies, anomalies.final_score, plot=True, N_vals=N_vals)\n",
    "plt.figure(figsize=figsize_square)\n",
    "plt.plot(N_vals, rws_after, label='Active learning')\n",
    "plt.plot(N_vals, rws_before, label='No active learning')\n",
    "plt.xlim([10,500])\n",
    "plt.ylim([0,1.05])\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('Rank Weighted Score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir+'galaxy_rws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_dataset = ImageThumbnailsDataset(directory=data_dir, transform_function=image_transform_scale, \n",
    "                                       output_dir=out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=12\n",
    "nrows = 2\n",
    "ncols = 6\n",
    "\n",
    "examples_figure_size = figsize_panels\n",
    "\n",
    "if presentation_plots:\n",
    "    nrows = 3\n",
    "    ncols = 4\n",
    "    examples_figure_size = presentation_plot_size\n",
    "\n",
    "left = 0.005\n",
    "right = 0.99\n",
    "bottom = 0.05\n",
    "top = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89760c7cdc584907a19225c4ff7009ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=examples_figure_size)\n",
    "\n",
    "inds = np.random.choice(features.index, size=N, replace=False)\n",
    "for i in range(N):\n",
    "    plt.subplot(nrows, ncols, i+1)\n",
    "    plt.imshow(image_dataset.get_sample(inds[i]))\n",
    "    plt.gca().axis('off')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=left, right=right, bottom=bottom, top=top)\n",
    "\n",
    "plt.savefig(fig_dir + 'galaxy_examples_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before HITL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cabef8b45e49cd876f07b29bfadc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "fig = plt.figure(figsize=examples_figure_size)\n",
    "\n",
    "wd = 20 # Thickness of box line in pixels\n",
    "col = [1,0,0]\n",
    "\n",
    "inds = anomalies.sort_values('score', ascending=False).index[:N]\n",
    "for i in range(N):\n",
    "    plt.subplot(nrows, ncols, i+1)\n",
    "    img = image_dataset.get_sample(inds[i])\n",
    "    if i in [1,4,6]:\n",
    "        img[0:wd, :] = col\n",
    "        img[img.shape[0]-wd:img.shape[0], :] = col\n",
    "        img[:, 0:wd] = col\n",
    "        img[:, img.shape[1]-wd:img.shape[1]] = col\n",
    "    plt.imshow(img)\n",
    "    plt.gca().axis('off')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=left, right=right, bottom=bottom, top=top)\n",
    "\n",
    "plt.savefig(fig_dir + 'galaxy_examples_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After HITL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51ea6df983a4609b368f8f06eea0902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=examples_figure_size)\n",
    "\n",
    "anomalies = anomalies.sort_values('final_score', ascending=False)\n",
    "#inds = anomalies.loc[anomalies.human_label == -1].index[:N]\n",
    "inds = anomalies.index[:N]\n",
    "for i in range(N):\n",
    "    plt.subplot(nrows, ncols, i+1)\n",
    "    plt.imshow(image_dataset.get_sample(inds[i]))\n",
    "    plt.gca().axis('off')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=left, right=right, bottom=bottom, top=top)\n",
    "\n",
    "plt.savefig(fig_dir + 'galaxy_examples_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE anomaly score plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSNE(angle=0.5, early_exaggeration=12.0, init='random', learning_rate=200.0,\n",
       "     method='barnes_hut', metric='euclidean', min_grad_norm=1e-07,\n",
       "     n_components=2, n_iter=1000, n_iter_without_progress=300, n_jobs=None,\n",
       "     perplexity=30, random_state=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = anomalies.sort_values('score', ascending=False).index[:2000]\n",
    "\n",
    "ts = TSNE(perplexity=30)\n",
    "ts.fit(features.loc[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ts.embedding_\n",
    "X[:,0] = (X[:,0] - X[:,0].min())/(X[:,0].max()-X[:,0].min())\n",
    "X[:,1] = (X[:,1] - X[:,1].min())/(X[:,1].max()-X[:,1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(X[:,0].min(), X[:,0].max(), 200)\n",
    "y = np.linspace(X[:,1].min(), X[:,1].max(), 200)\n",
    "xgrid, ygrid = np.meshgrid(x, y)\n",
    "zgrid = griddata(X, anomalies.loc[inds,'score'].values, (xgrid, ygrid), method='nearest')\n",
    "zgrid2 = griddata(X, anomalies.loc[inds,'final_score'].values, (xgrid, ygrid), method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d06ac23b49143ffabdbf2eb3769d8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=figsize_fullwidth)\n",
    "\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "im1=ax1.imshow(zgrid, origin='lower', extent=(x.min(), x.max(), y.min(),y.max()), cmap='magma')\n",
    "# plt.scatter(X[:,0], X[:,1], c=anomalies.loc[inds,'score'], s=10, cmap='magma')\n",
    "\n",
    "\n",
    "\n",
    "for lab in np.unique(anomalies.human_label)[1:]:\n",
    "    msk = np.where(anomalies.loc[inds, 'human_label'] == lab)\n",
    "#     plt.scatter(X[msk,0], X[msk,1], facecolors='none', edgecolors=cols[lab], s=15, marker='s',alpha=0.5)\n",
    "    plt.scatter(X[msk,0], X[msk,1], c='k', s=25, marker='$%d$' %lab, linewidths=0.5)\n",
    "    plt.scatter(X[msk,0], X[msk,1], c='w', s=20, marker='$%d$' %lab, linewidths=0.5)\n",
    "\n",
    "plt.xlabel('Raw anomaly score')\n",
    "\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.colorbar(im1, cax=cax)\n",
    "\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "im2=ax2.imshow(zgrid2, origin='lower', cmap='magma', extent=(x.min(), x.max(), y.min(),y.max()))\n",
    "\n",
    "# plt.scatter(X[:,0], X[:,1], c=anomalies.loc[inds,'score'], s=10, cmap='magma')\n",
    "\n",
    "\n",
    "for lab in np.unique(anomalies.human_label)[1:]:\n",
    "    msk = np.where(anomalies.loc[inds, 'human_label'] == lab)\n",
    "    plt.scatter(X[msk,0], X[msk,1], c='k', s=25, marker='$%d$' %lab, linewidths=0.5)\n",
    "    plt.scatter(X[msk,0], X[msk,1], c='w', s=20, marker='$%d$' %lab, linewidths=0.5)\n",
    "    \n",
    "plt.xlabel('Trained anomaly score')\n",
    "\n",
    "\n",
    "\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "fig.colorbar(im2, cax=cax)\n",
    "\n",
    "plt.subplots_adjust(wspace=10, top=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(fig_dir+'galaxy_feature_space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xvals = np.arange(0, N_outliers, n_recompute)+n_recompute\n",
    "# perc_no_hitl = []\n",
    "# for x in xvals:\n",
    "#     n = labels.loc[anomalies.sort_values('score', ascending=False).index[:x]].label.sum()\n",
    "#     perc_no_hitl.append(n/labels.label.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(np.arange(0, N_outliers, n_recompute)+n_recompute, np.array(perc)*labels.label.sum())\n",
    "# plt.plot(xvals, np.array(perc_no_hitl)*labels.label.sum())\n",
    "# plt.legend(('HITL', 'ML'))\n",
    "# plt.xlabel('Number of Labelled Examples')\n",
    "# plt.ylabel('Cumulative Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(np.arange(0, N_outliers, n_recompute)+n_recompute, RWS)\n",
    "# plt.legend()\n",
    "# plt.xlabel('Number of Labelled Examples')\n",
    "# plt.ylabel('Rank Weighted Score N=150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before any active learning\n",
    "# scores = anomalies.score.values\n",
    "# msk = anomalies.human_label==-1\n",
    "# N_vals, rws_before = make_rws_curve(labels.loc[msk], anomalies.loc[msk], anomalies.loc[msk, 'score'], plot=True)\n",
    "# N_vals, rws_after = make_rws_curve(labels.loc[msk], anomalies.loc[msk], anomalies.loc[msk].final_score, plot=True)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot([100, 100], [0,0.4], '--k', alpha=0.5)\n",
    "# plt.plot(N_vals, rws_before, label='Without HITL')\n",
    "# plt.plot(N_vals, rws_after, label='With HITL')\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlim([0,250])\n",
    "# plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astronomaly.preprocessing import image_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_spiral = '949415'\n",
    "f_elliptical = '824608'\n",
    "f_merger = '516751'\n",
    "f_skinny = '565692'\n",
    "f_star = '732929'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776f77a3cd50482b8a63447c7dba0903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa18f422df0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image_dataset.get_sample(anomalies.index[13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img, flname, figsize):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(img)\n",
    "    plt.gca().axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_dir+flname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888777b60d9442a09b8b47c1f232e866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gal_type = 'star'\n",
    "if gal_type == 'normal':\n",
    "    ind = f_spiral\n",
    "elif gal_type == 'star':\n",
    "    ind = f_star\n",
    "else:\n",
    "    ind = f_merger\n",
    "    \n",
    "img = image_dataset.get_sample(ind)\n",
    "\n",
    "plot_image(img, 'galaxy_'+gal_type+'_1', figsize_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876b22de889544cc82eb39ab937b4747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_clipped = image_preprocessing.image_transform_sigma_clipping(img)\n",
    "plot_image(img_clipped, 'galaxy_'+gal_type+'_2', figsize_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles=[90, 80, 70, 60, 50, 0]\n",
    "chosen_percentiles = [90, 50, 0]\n",
    "this_image = img_clipped.copy()[:,:,0]\n",
    "image_contours = img_clipped.copy()\n",
    "\n",
    "contours_dict = {}\n",
    "\n",
    "x0 = y0 = -1\n",
    "x_cent = this_image.shape[0] // 2\n",
    "y_cent = this_image.shape[1] // 2\n",
    "\n",
    "for p in percentiles:\n",
    "    thresh = np.percentile(this_image[this_image > 0], p)\n",
    "    contours, hierarchy = shape_features.find_contours(this_image, thresh)\n",
    "\n",
    "    x_contours = np.zeros(len(contours))\n",
    "    y_contours = np.zeros(len(contours))\n",
    "\n",
    "    # First attempt to find the central point of the inner most contour\n",
    "    if len(contours) != 0:\n",
    "        for k in range(len(contours)):\n",
    "            M = cv2.moments(contours[k])\n",
    "            try:\n",
    "                x_contours[k] = int(M[\"m10\"] / M[\"m00\"])\n",
    "                y_contours[k] = int(M[\"m01\"] / M[\"m00\"])\n",
    "            except ZeroDivisionError:\n",
    "                pass\n",
    "        if x0 == -1:\n",
    "            x_diff = x_contours - x_cent\n",
    "            y_diff = y_contours - y_cent\n",
    "        else:\n",
    "            x_diff = x_contours - x0\n",
    "            y_diff = y_contours - y0\n",
    "\n",
    "        # Will try to find the CLOSEST contour to the central one\n",
    "        r_diff = np.sqrt(x_diff**2 + y_diff**2)\n",
    "\n",
    "        ind = np.argmin(r_diff)\n",
    "\n",
    "        if x0 == -1:\n",
    "            x0 = x_contours[ind]\n",
    "            y0 = y_contours[ind]\n",
    "\n",
    "        c = contours[ind]\n",
    "        \n",
    "        contours_dict[p] = c\n",
    "    if p in chosen_percentiles:\n",
    "        image_contours = shape_features.draw_contour(c, image_contours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6ec64507b14a93b37e3c2b0a6a3872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(image_contours, 'galaxy_'+gal_type+'_3', figsize_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f111b99dd645bdaeb0d5576e88f065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ellipse_image = img_clipped.copy()\n",
    "for p in percentiles:\n",
    "    if p in chosen_percentiles:\n",
    "        ellipse_image = shape_features.fit_ellipse(contours_dict[p], ellipse_image, filled=False)\n",
    "plot_image(ellipse_image, 'galaxy_'+gal_type+'_4', figsize_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Darg merger catalogue and other groups catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = anomalies.merge(kaggle_key, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michelle/miniconda3/envs/astronomaly/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (1,2,3,6,7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "groups_cat = pd.read_csv('/home/michelle/BigData/Anomaly/GalaxyZoo/groups_catalogue.tsv', delimiter=';', comment='#')\n",
    "groups_cat = groups_cat[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies['group'] = np.zeros(len(anomalies))\n",
    "group_obj_ids = anomalies.merge(groups_cat, left_on='dr7objid', right_on='objID', how='inner', left_index=True).objID\n",
    "anomalies.loc[np.in1d(anomalies.dr7objid, group_obj_ids), 'group'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergers = pd.read_csv('/home/michelle/BigData/Anomaly/GalaxyZoo/darg_mergers.csv')\n",
    "merger_objs = list(mergers.object1)+list(mergers.object2)\n",
    "merger_objs = np.unique(merger_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies['merger'] = np.zeros(len(anomalies))\n",
    "anomalies.loc[np.in1d(anomalies.dr7objid, merger_objs), 'merger'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = anomalies.sort_values('final_score', ascending=False)\n",
    "\n",
    "merger_cum_sum = np.zeros(len(anomalies))\n",
    "group_cum_sum = np.zeros(len(anomalies))\n",
    "total_cum_sum = np.zeros(len(anomalies))\n",
    "rand_cum_sum = np.zeros(len(anomalies))\n",
    "\n",
    "total_anoms = (anomalies.group==1)|(anomalies.merger==1)\n",
    "\n",
    "rand_list = np.random.choice(total_anoms, size=len(total_anoms), replace=False)\n",
    "\n",
    "for i in range(len(anomalies)):\n",
    "    merger_cum_sum[i] = anomalies['merger'][:i].sum()\n",
    "    group_cum_sum[i] = anomalies['group'][:i].sum()\n",
    "    total_cum_sum[i] = merger_cum_sum[i] + group_cum_sum[i]\n",
    "    rand_cum_sum[i] = rand_list[:i].sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_mergers = anomalies.merger.sum()\n",
    "N_groups = anomalies.group.sum()\n",
    "N_anoms = N_mergers + N_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0892bedfaedc4045939e43a4d324b333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f668a2a3940>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,9), dpi=100)\n",
    "plt.plot([len(anomalies)*0.1, len(anomalies)*0.1], [0,1], 'k--', alpha=0.5)\n",
    "plt.plot(total_cum_sum/N_anoms)\n",
    "plt.plot(merger_cum_sum/N_mergers)\n",
    "plt.plot(group_cum_sum/N_groups)\n",
    "plt.plot(rand_cum_sum/N_anoms, 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = []\n",
    "for idx in anomalies.index[:200]:\n",
    "    if not anomalies.loc[idx, 'group'] and not anomalies.loc[idx, 'merger'] and not idx in df[df['Class8.6']>0.8].index:\n",
    "        inds.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for idx in inds:\n",
    "    imgs.append(image_dataset.get_sample(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f1e22c007f4a93bb3590bcd2e6693f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update({'figure.dpi':100})\n",
    "cycler = ImageCycler(imgs, xlabels=inds)\n",
    "cycler.cycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dr7objid    588013383816904793\n",
       "Usage                 training\n",
       "Name: 373505, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_key.loc['373505']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['100520', '108742', '127231', '133499', '155564', '176576', '180253',\n",
       "       '236236', '271943', '316412', '330517', '333669', '350139', '373505',\n",
       "       '395411', '398159', '407825', '430220', '433488', '446716', '487641',\n",
       "       '489626', '499023', '501768', '516751', '524354', '553727', '577678',\n",
       "       '626793', '637115', '647440', '654297', '670070', '674805', '696497',\n",
       "       '700256', '714674', '718275', '726532', '735007', '769081', '790978',\n",
       "       '803787', '807226', '813394', '826038', '833171', '855799', '912722',\n",
       "       '925544', '938173', '938264', '968553'],\n",
       "      dtype='object', name='GalaxyID')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated training plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies2 = anomalies[['score', 'human_label', 'final_score']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Running NeighbourScore ...\n",
      "Done! Time taken: 2.522036552429199 s\n",
      "\n",
      "100\n",
      "Running NeighbourScore ...\n",
      "Done! Time taken: 3.2990734577178955 s\n",
      "\n",
      "200\n",
      "Running NeighbourScore ...\n",
      "Done! Time taken: 2.68585467338562 s\n",
      "\n",
      "300\n",
      "Running NeighbourScore ...\n",
      "Done! Time taken: 3.035444736480713 s\n",
      "\n",
      "400\n",
      "Running NeighbourScore ...\n",
      "Done! Time taken: 3.2974531650543213 s\n",
      "\n",
      "500\n",
      "Running NeighbourScore ...\n",
      "Done! Time taken: 3.4656612873077393 s\n",
      "\n",
      "600\n",
      "Running NeighbourScore ...\n",
      "Done! Time taken: 4.0316572189331055 s\n",
      "\n",
      "700\n",
      "Running NeighbourScore ...\n",
      "Done! Time taken: 3.86476469039917 s\n",
      "\n",
      "800\n",
      "Running NeighbourScore ...\n",
      "Done! Time taken: 4.517053127288818 s\n",
      "\n",
      "900\n",
      "Running NeighbourScore ...\n",
      "Done! Time taken: 4.416330575942993 s\n",
      "\n",
      "1000\n",
      "Running NeighbourScore ...\n",
      "Done! Time taken: 4.593501091003418 s\n",
      "\n",
      "Time 121.45626759529114\n"
     ]
    }
   ],
   "source": [
    "n_recompute = 100\n",
    "N_outliers = 1100\n",
    "rerun = True\n",
    "    \n",
    "if rerun:\n",
    "\n",
    "    anomalies2['human_label'] = np.array([-1]*len(anomalies2), dtype='int')\n",
    "    anomalies2['final_score'] = anomalies2.score\n",
    "\n",
    "    RWS = np.zeros(N_outliers//n_recompute)\n",
    "    perc = np.zeros(N_outliers//n_recompute)\n",
    "    total = np.zeros(N_outliers//n_recompute)\n",
    "\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    for n in range(N_outliers//n_recompute):\n",
    "        print((anomalies2.human_label!=-1).sum())\n",
    "\n",
    "        anomalies2 = anomalies2.sort_values('final_score', ascending=False)\n",
    "        inds = anomalies2.loc[anomalies2.human_label==-1].index[:n_recompute]\n",
    "        anomalies2.loc[inds, 'human_label'] = labels.loc[inds, 'human_label']\n",
    "\n",
    "        ns = NeighbourScore(alpha=0.1, force_rerun=True, output_dir = out_dir)\n",
    "        features_with_labels = ns.combine_data_frames(features, anomalies2)\n",
    "        final_score = ns.run(features_with_labels)\n",
    "        anomalies2['final_score'] = final_score.trained_score\n",
    "        \n",
    "        anomalies2 = anomalies2.sort_values('final_score', ascending=False)\n",
    "\n",
    "        this_rws = make_rws_curve(labels, anomalies2, anomalies2.final_score, plot=False)\n",
    "        RWS[n] = this_rws\n",
    "\n",
    "        tot = (labels.loc[anomalies2.index[anomalies2.human_label!=-1]].label==1).sum()\n",
    "        perc[n] = tot/((labels.label==1).sum())\n",
    "        total[n] = tot\n",
    "\n",
    "        print()\n",
    "\n",
    "\n",
    "    print('Time', time.time()-t1)\n",
    "\n",
    "    anomalies2.to_parquet('anomalies_gz.parquet')\n",
    "    np.save('percentages_gz.npy', perc)\n",
    "    np.save('rws_gz.npy', RWS)\n",
    "    np.save('total_gz.npy', total)\n",
    "    \n",
    "else:\n",
    "    anomalies = pd.read_parquet('anomalies_gz.parquet')\n",
    "    perc = np.load('percentages_gz.npy')\n",
    "    RWS = np.load('rws_gz.npy')\n",
    "    total = np.load('total_gz.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c4207c3b014e8a978b400d11e49eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=figsize_square)\n",
    "plt.plot(np.arange(0, N_outliers, n_recompute)+n_recompute, total)\n",
    "plt.xlabel('Number of Labelled Examples')\n",
    "plt.ylabel('Number of Anomalies Found')\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(fig_dir+'sim_cumulative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf5240423a947f98b2856fed1c72d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=figsize_square)\n",
    "\n",
    "plt.plot(np.arange(0, N_outliers, n_recompute)+n_recompute, RWS)\n",
    "# plt.legend(loc='best')\n",
    "plt.xlabel('Number of Labelled Examples')\n",
    "plt.ylabel('Rank Weighted Score N=150')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(fig_dir+'sim_rws_150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
